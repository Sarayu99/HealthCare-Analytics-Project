{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsKVE+bB6ohBT0rg5LjIct"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Health Care Analytics Project\n","---\n","This notebook runs the anomaly detection code on the health care data set <br>\n","\n","Anomaly Detection Transformer Paper link- [here](https://iclr.cc/virtual/2022/spotlight/7024) <br>\n","Anomaly Detection Transformer Code link- [here](https://github.com/thuml/Anomaly-Transformer)\n","\n","Topics in the notebook <br>\n","\n","1. Reading the health data\n","2. DataLoader\n","3. Embeddings\n","4. Attention\n","5. Encoder\n","6. Main\n","\n","##### @Notebook author: Sarayu Vyakaranam (svyakara@purdue.edu)\n","\n","---\n","---"],"metadata":{"id":"4nY_JyWjcUWs"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"76aqQ5U7cyZj"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"Zq0s4gdLczCL"}},{"cell_type":"markdown","source":["---\n","\n","1. Reading the health data\n","\n","---"],"metadata":{"id":"xqJihDWpcv1Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0boLxWK_beqi"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import os\n","import random\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68KBvs9zc55y","executionInfo":{"status":"ok","timestamp":1692644016569,"user_tz":240,"elapsed":23254,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"f80a20ce-03ae-4388-b4bf-dd9bcff51cfe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/no_missing_336.csv',index_col=0)\n","print(len(data))\n","data.head(4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"2Q_p9AOSdD2i","executionInfo":{"status":"ok","timestamp":1692644018115,"user_tz":240,"elapsed":1549,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"d23b53bb-d2dd-4a83-a9e0-2dc05d487612"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["336\n"]},{"output_type":"execute_result","data":{"text/plain":["                  date  heart_rate  steps  minutes_sedentary  \\\n","0  2021-09-03 00:00:00   96.636364    367                 24   \n","1  2021-09-03 01:00:00   92.766667    268                 43   \n","2  2021-09-03 02:00:00   81.508475      0                 59   \n","3  2021-09-03 03:00:00   80.583333      0                 60   \n","\n","   minutes_lightly_active  minutes_fairly_active  minutes_very_active  \n","0                      20                      0                    0  \n","1                      17                      0                    0  \n","2                       0                      0                    0  \n","3                       0                      0                    0  "],"text/html":["\n","  <div id=\"df-6367c2fa-7dbb-4fc3-846e-426c68466e95\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>heart_rate</th>\n","      <th>steps</th>\n","      <th>minutes_sedentary</th>\n","      <th>minutes_lightly_active</th>\n","      <th>minutes_fairly_active</th>\n","      <th>minutes_very_active</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-09-03 00:00:00</td>\n","      <td>96.636364</td>\n","      <td>367</td>\n","      <td>24</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-09-03 01:00:00</td>\n","      <td>92.766667</td>\n","      <td>268</td>\n","      <td>43</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-09-03 02:00:00</td>\n","      <td>81.508475</td>\n","      <td>0</td>\n","      <td>59</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-09-03 03:00:00</td>\n","      <td>80.583333</td>\n","      <td>0</td>\n","      <td>60</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6367c2fa-7dbb-4fc3-846e-426c68466e95')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6367c2fa-7dbb-4fc3-846e-426c68466e95 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6367c2fa-7dbb-4fc3-846e-426c68466e95');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4cb8e73f-23cd-43ef-9222-dc9f80f4e300\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cb8e73f-23cd-43ef-9222-dc9f80f4e300')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4cb8e73f-23cd-43ef-9222-dc9f80f4e300 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#code from shiyang\n","import random\n","def create_random_boolean_vector(length, probability_of_true):\n","    vector = []\n","    for i in range(length):\n","        vector.append(random.random() < probability_of_true)\n","    return vector\n","nlength = 336 # total length. If you did the split, change the length here!!!!\n","#vector is a list\n","vector = create_random_boolean_vector(nlength, 0.1)\n","#convert list to array\n","label = np.array(vector)"],"metadata":{"id":"Vv82M60BfLTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haOmlWk_gbQ_","executionInfo":{"status":"ok","timestamp":1692644018115,"user_tz":240,"elapsed":17,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"25180ebe-7cf9-471e-cd6c-633fcc3874e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False,  True, False, False,\n","        True, False,  True, False, False, False, False, False, False,\n","       False, False, False, False, False,  True,  True, False, False,\n","       False, False, False, False, False, False, False,  True, False,\n","       False, False, False, False, False, False, False,  True, False,\n","       False, False, False,  True, False, False, False, False, False,\n","       False, False, False, False, False, False, False,  True, False,\n","       False,  True, False,  True, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False,  True,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False,  True, False, False, False, False, False, False, False,\n","        True, False, False,  True, False, False, False, False, False,\n","        True, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False,  True, False, False, False,\n","       False,  True, False, False,  True, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False,  True, False,  True, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","        True, False, False, False, False, False, False, False, False,\n","       False, False, False,  True, False, False, False,  True, False,\n","       False, False,  True, False, False, False, False,  True, False,\n","       False, False,  True, False, False,  True, False, False, False,\n","       False, False, False, False, False,  True, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False,  True, False,  True,\n","        True, False, False, False, False, False, False,  True, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#data['labels'] = label.tolist() #code to add the labels to the opriginal data"],"metadata":{"id":"1odBpRMIhK2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"j0f-KbarhOdz","executionInfo":{"status":"ok","timestamp":1692644018116,"user_tz":240,"elapsed":16,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"1a1dcb58-532e-44d4-884f-65bfe24a909d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  date  heart_rate  steps  minutes_sedentary  \\\n","0  2021-09-03 00:00:00   96.636364    367                 24   \n","1  2021-09-03 01:00:00   92.766667    268                 43   \n","2  2021-09-03 02:00:00   81.508475      0                 59   \n","\n","   minutes_lightly_active  minutes_fairly_active  minutes_very_active  \n","0                      20                      0                    0  \n","1                      17                      0                    0  \n","2                       0                      0                    0  "],"text/html":["\n","  <div id=\"df-0eb1b6eb-b710-4f04-9771-38be4cf3d066\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>heart_rate</th>\n","      <th>steps</th>\n","      <th>minutes_sedentary</th>\n","      <th>minutes_lightly_active</th>\n","      <th>minutes_fairly_active</th>\n","      <th>minutes_very_active</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-09-03 00:00:00</td>\n","      <td>96.636364</td>\n","      <td>367</td>\n","      <td>24</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-09-03 01:00:00</td>\n","      <td>92.766667</td>\n","      <td>268</td>\n","      <td>43</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-09-03 02:00:00</td>\n","      <td>81.508475</td>\n","      <td>0</td>\n","      <td>59</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0eb1b6eb-b710-4f04-9771-38be4cf3d066')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0eb1b6eb-b710-4f04-9771-38be4cf3d066 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0eb1b6eb-b710-4f04-9771-38be4cf3d066');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1de18a43-6a82-45c7-8ced-d1bc05712873\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1de18a43-6a82-45c7-8ced-d1bc05712873')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1de18a43-6a82-45c7-8ced-d1bc05712873 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["data_wtime = data.drop(\"date\", axis=1) # Drop the time column"],"metadata":{"id":"ULL9SH1f08ng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X= data_wtime[['heart_rate','steps','minutes_sedentary','minutes_lightly_active','minutes_fairly_active','minutes_very_active']]\n","y=data_wtime[[]]\n","#train test split\n","X_train, X_test,_,_ = train_test_split(X,y ,random_state=104, test_size=0.25, shuffle=True)\n","print('X_train : ')\n","print(X_train.head())\n","print('')\n","print('X_test : ')\n","print(X_test.head())\n","print('')\n","print('-----lengths-----')\n","print(len(X_train),len(X_test)) #75-25 split"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6KW5I00fzu0","executionInfo":{"status":"ok","timestamp":1692644018818,"user_tz":240,"elapsed":717,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"5a4d278c-8ba3-41f9-ab6b-ab9492031000"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train : \n","     heart_rate  steps  minutes_sedentary  minutes_lightly_active  \\\n","90    80.950000     25                 58                       2   \n","5     82.016667     14                 56                       4   \n","254   70.066667      0                 60                       0   \n","104   83.600000      0                 60                       0   \n","196   79.600000      0                 60                       0   \n","\n","     minutes_fairly_active  minutes_very_active  \n","90                       0                    0  \n","5                        0                    0  \n","254                      0                    0  \n","104                      0                    0  \n","196                      0                    0  \n","\n","X_test : \n","     heart_rate  steps  minutes_sedentary  minutes_lightly_active  \\\n","265   75.133333     35                 57                       3   \n","9     77.033333     61                 56                       4   \n","84    77.933333      0                 60                       0   \n","122   84.366667      0                 60                       0   \n","17    80.783333     83                 55                       5   \n","\n","     minutes_fairly_active  minutes_very_active  \n","265                      0                    0  \n","9                        0                    0  \n","84                       0                    0  \n","122                      0                    0  \n","17                       0                    0  \n","\n","-----lengths-----\n","252 84\n"]}]},{"cell_type":"markdown","source":["---\n","2. DataLoader\n","---"],"metadata":{"id":"fsIho1mmiI3Y"}},{"cell_type":"markdown","source":["DataLoader\n","\n","* __len__ function\n","\n","The __len__ function in the SMDSegLoader class is a special function that returns the length of the data loader. The length of the data loader is the number of data samples that can be loaded by the data loader.the function returns the number of data samples in the validation set that can be divided into windows of size win_size with a step size of step.\n","\n","The win_size is subtracted from self.test.shape[0] before dividing by self.step + 1 because the win_size represents the number of data samples in each window. If the division was done without subtracting the win_size, the length of the data loader would be incorrect.\n","(below doesnt amke sense to me?)\n","For example, let's say we have a data loader with a window size of 10 and a step size of 2. This means that the first batch will contain the data samples from index 0 to index 9, the second batch will contain the data samples from index 2 to index 11, and so on. The last batch will contain the data samples from index 8 to index 17.\n","The __len__ function needs to take this into account when calculating the length of the data loader. If the division was done without subtracting the win_size, the length of the data loader would be 18. However, there are only 17 data.(?)\n","\n","* __getitem__ function\n","\n","The line of code np.float32(self.train[index:index + self.win_size]), np.float32(self.test_labels[0:self.win_size]) in the __getitem__ function of the SMDSegLoader class converts the data sample and ground truth labels to float32 format. This is done because the transformer model expects the data and labels to be in float32 format.\n","\n","The self.train variable is the training data, and the self.test_labels variable is the ground truth labels for the training data. The index variable is the index of the data sample to return. The self.win_size variable is the window size of the data loader.\n","\n","why does the test_labels start from 0 but train/val start from idnex- The ground truth labels are always returned as the first win_size values because the transformer model needs to learn to predict the next token based on the previous tokens. If the ground truth labels were not always returned as the first win_size values, then the transformer model would not be able to learn to predict the next token accurately.\n","\n","during testing, teh ground truth variables for teh current window are only selected\n","\n","* Batch vs window\n","\n","Q-> isnt win_size serving the role of a batch_size here? what is teh need for batch size then? <br>\n","A: Yes, the win_size variable can be considered as a batch size in this case. However, the batch size is a more general concept that refers to the number of data samples that are processed together by the model. The win_size is a specific implementation of the batch size that is used in the SMDSegLoader class.\n","\n","Q->\n","then why need teh batch_size in teh get_loader_segment class where the SMAPSegLoader(object) class is called? does a given batch have multiple windows? <br>\n","A:The batch size is still needed in the get_loader_segment class because it controls the number of data samples that are processed together by the model. The SMDSegLoader class divides the data into windows, but the model still needs to process the windows one at a time.<br>\n","A given batch can have multiple windows, but the number of windows in a batch will depend on the batch size and the win_size. For example, if the batch size is 10 and the win_size is 2, then a batch will contain 5 windows."],"metadata":{"id":"fYTYGK4VblFG"}},{"cell_type":"code","source":["pip install dataloader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruIFw7Kzkcut","executionInfo":{"status":"ok","timestamp":1692644025083,"user_tz":240,"elapsed":6268,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"323b0f2e-1cae-4815-dcb5-7bfac6d0e34c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dataloader\n","  Downloading dataloader-2.0.tar.gz (9.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: dataloader\n","  Building wheel for dataloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dataloader: filename=dataloader-2.0-py3-none-any.whl size=10085 sha256=5a3c772a31ff5cf636da50cdac944e42884f4fa126c1248f38d3bd6625b4b682\n","  Stored in directory: /root/.cache/pip/wheels/60/56/53/2b1c14a2abb6f40f1d59f97461a59e61f326433fac416794de\n","Successfully built dataloader\n","Installing collected packages: dataloader\n","Successfully installed dataloader-2.0\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","#using only the SMAP class from the 'data_loader.py' file\n","class healthdata(object):\n","    def __init__(self, win_size, step, mode=\"train\"):\n","        #data_path needs to be set as per data location in local computer. For me is is- '/content/gdrive/MyDrive/Colab Notebooks/'\n","        #initilizations\n","        self.mode = mode\n","        #step is the step size of the data loader. It controls the overlap between subsequent windows. A larger step size will result in less overlap between subsequent batches, while a smaller step size will result in more overlap\n","        self.step = step\n","        self.win_size = win_size\n","        #set scaler\n","        self.scaler = StandardScaler()\n","        #add path to train data\n","        train_data = X_train\n","        #pass train data to scaler and transform\n","        self.scaler.fit(train_data)\n","        train_data = self.scaler.transform(train_data)\n","        #repeat same for test data\n","        test_data = X_test\n","        self.test = self.scaler.transform(test_data)\n","\n","        #store scaled and transformed train and test data\n","        self.train = train_data\n","        #load the test labels\n","        vector = create_random_boolean_vector(nlength, 0.1)\n","        #convert list to array\n","        label = np.array(vector)\n","        self.test_labels = label\n","        print(\"test:\", self.test.shape)\n","        print(\"train:\", self.train.shape)\n","\n","    def __len__(self):\n","\n","        #returning the length of input considered\n","        if self.mode == \"train\":\n","            return (self.train.shape[0] - self.win_size) // self.step + 1 #233\n","        elif (self.mode == 'test'):\n","            return (self.test.shape[0] - self.win_size) // self.step + 1\n","        else:\n","            print(\"here\")\n","            return (self.test.shape[0] - self.win_size) // self.win_size + 1\n","\n","\n","    def __getitem__(self, index):\n","        index = index * self.step\n","        '''\n","        if self.mode == \"train\":\n","            return np.float32(self.train[index:index + self.win_size]), np.float32(self.test_labels[0:self.win_size])\n","        elif (self.mode == 'test'):\n","            return np.float32(self.test[index:index + self.win_size]), np.float32(self.test_labels[index:index + self.win_size])\n","        '''\n","        if self.mode == \"train\":\n","            return np.float32(self.train[index:index + self.win_size])\n","        elif (self.mode == 'test'):\n","            return np.float32(self.test[index:index + self.win_size]), np.float32(self.test_labels[index:index + self.win_size])\n","        else:\n","            return np.float32(self.test[index // self.step * self.win_size:index // self.step * self.win_size + self.win_size]), np.float32(self.test_labels[index // self.step * self.win_size:index // self.step * self.win_size + self.win_size])"],"metadata":{"id":"J7srdNxgbnCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape[0]) #note\n","print(X_train.shape[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujVmWOyY2owF","executionInfo":{"status":"ok","timestamp":1692644025636,"user_tz":240,"elapsed":25,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"076b4738-521b-4d33-87c0-bc8bdc8cca44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["252\n","6\n"]}]},{"cell_type":"code","source":["#modified function from 'data_loader.py'\n","def get_loader_segment(batch_size, win_size=100, step=100, mode='train'):\n","    batch = batch_size\n","    dataset = healthdata(win_size, 1, mode)\n","\n","    shuffle = False\n","    if mode == 'train':\n","        shuffle = True\n","\n","    print(batch_size)\n","    data_loader = DataLoader(dataset=dataset,batch_size=batch,shuffle=shuffle,num_workers=0)\n","    return data_loader"],"metadata":{"id":"jieqcOFEi3Tq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["can skip: the code below in this section is simplyu to experiment with the data loader, dataloader will be called again in the main model"],"metadata":{"id":"aAQN_7oJ99l3"}},{"cell_type":"code","source":["train_loader = get_loader_segment(batch_size=8, win_size=20,mode='train')\n","test_loader = get_loader_segment(batch_size=8, win_size=20,mode='test')\n","thre_loader = get_loader_segment(batch_size=8, win_size=20, mode='thre')\n","thre_loader.__len__()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C93FOTvgk45T","executionInfo":{"status":"ok","timestamp":1692644025636,"user_tz":240,"elapsed":22,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"262d6e92-12c5-42be-b441-484b7976963b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test: (84, 6)\n","train: (252, 6)\n","8\n","test: (84, 6)\n","train: (252, 6)\n","8\n","test: (84, 6)\n","train: (252, 6)\n","8\n","here\n"]},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["#understanding the data loader better and seeing the normalized values\n","for batch,label in train_loader:\n","  #note each batch is 8 observations, each observation is 20X6\n","  print(len(batch))\n","  print(len(label))\n","  print(batch)\n","  print(label)\n","  print('-------')\n","  #note each sigma is 1X20, so for the total batch there are 8X20 rows\n","  print(batch.shape)\n","  print(label.shape)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTOV0MkZlJMT","executionInfo":{"status":"ok","timestamp":1692644025636,"user_tz":240,"elapsed":20,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"c9a566dd-c5b3-4b9f-d967-d7ffa515f871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8\n","8\n","tensor([[[-0.0567, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.0121,  0.7564, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-0.3908, -0.3105,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 2.3609,  4.4217, -4.1734,  4.7783,  0.0000,  0.0000],\n","         [ 0.2848, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.8822, -0.4998,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.4445, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.9187,  0.4983, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [ 0.2996, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.2114, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.5797,  1.7373, -2.2677,  2.6208,  0.0000,  0.0000],\n","         [-0.4350,  0.5843, -0.8385,  1.0027,  0.0000,  0.0000],\n","         [-0.8478, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.7642,  0.0337,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 1.1546, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.1473, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.5358, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 1.3045, -0.4826,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.8696,  2.9418, -1.7913,  2.0815,  0.0000,  0.0000],\n","         [-0.3662, -0.0180,  0.1144, -0.0760,  0.0000,  0.0000]],\n","\n","        [[-0.5235,  1.4447, -1.0767,  1.2724,  0.0000,  0.0000],\n","         [ 1.0346, -0.0696, -0.1238, -0.0760,  0.0000,  0.0000],\n","         [-0.3662, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.3364, -0.2761,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.4450,  1.2210, -1.5531,  1.5421,  0.0000,  0.0000],\n","         [ 0.3438, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.5182, -0.5686, -0.1238, -0.6153,  0.0000,  0.0000],\n","         [ 0.4519, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.6021, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.3586, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.2286,  0.2746,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-0.5972, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.3070, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4645, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.7348, -0.1212, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [-0.9632, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-2.2556, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4326, -0.3277,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 1.5182,  2.3051, -2.5060,  2.8905,  0.0000,  0.0000],\n","         [-0.4129,  0.2918, -0.3620,  0.4634,  0.0000,  0.0000]],\n","\n","        [[ 1.3855, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 2.4272, -0.4826,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.0637, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4424, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.3735, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.8376, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.1915, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 1.0367,  0.1025, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-2.0099, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-2.4841, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.1992, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.9236, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.9482, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.2529, -0.2417,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 0.3586, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 2.3585,  1.3071, -1.0767,  1.2724,  0.0000,  0.0000],\n","         [-0.7446,  0.5843, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [ 1.5551, -0.4137,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-2.3858, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.2016, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]],\n","\n","        [[-0.7348, -0.1212, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [-0.9632, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-2.2556, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4326, -0.3277,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 1.5182,  2.3051, -2.5060,  2.8905,  0.0000,  0.0000],\n","         [-0.4129,  0.2918, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [ 0.0977,  1.1866, -1.3149,  1.2724,  0.0000,  0.0000],\n","         [ 0.4077,  1.0489, -1.0767,  1.2724,  0.0000,  0.0000],\n","         [-0.4448, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 1.0956,  0.1885, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [-0.2950, -0.4654,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.4151, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.7568,  0.5499,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 0.4396, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.0148, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.7495, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.2136,  0.2057,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 1.5084,  2.6149, -2.2677,  2.6208,  0.0000,  0.0000],\n","         [ 1.4469,  0.5155, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [-0.0960, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]],\n","\n","        [[-0.9043, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.1801, -0.5686,  0.3526, -0.6153,  0.0000,  0.0000],\n","         [-0.0247, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.1524,  0.0165,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 0.7983,  0.2574, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [-1.1008, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.0468, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.0072,  0.2230,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.2873, -0.1040,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [-1.7200, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.2947, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.8281, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.4915, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.1451, -0.3793,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-1.1254, -0.2072,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [-0.9289, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.9681, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.2038, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.0564,  0.1541,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-0.8355, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]],\n","\n","        [[-0.0935, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.9657, -0.4998,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.0220, -0.2761,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 2.0317,  0.2574, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-1.0222, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4596,  0.0853, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [ 1.7167, -0.4654,  0.1144, -0.3457,  0.0000,  0.0000],\n","         [ 0.6607,  0.9113, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-0.2311, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.6386,  0.2057,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 1.0981, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.2188,  0.6360, -1.0767,  1.2724,  0.0000,  0.0000],\n","         [ 1.7319, -0.4137,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-0.6905,  0.2057, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [-0.1918, -0.4654,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.1694,  0.1197, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-0.6242, -0.3449,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-1.5087, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.1033, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.0567, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]],\n","\n","        [[-1.0738,  0.4983, -0.8385,  1.0027,  0.0000,  0.0000],\n","         [-1.1500, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 1.4298, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-2.3710, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 1.1281, -0.5686, -0.3620, -0.6153,  0.0000,  0.0000],\n","         [ 0.7664,  2.2879, -2.5060,  2.8905,  0.0000,  0.0000],\n","         [ 0.6951, -0.2933,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [-0.2655, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.6927,  0.8252, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [-0.0935, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.9657, -0.4998,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.0220, -0.2761,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 2.0317,  0.2574, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-1.0222, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4596,  0.0853, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [ 1.7167, -0.4654,  0.1144, -0.3457,  0.0000,  0.0000],\n","         [ 0.6607,  0.9113, -0.6003,  0.7331,  0.0000,  0.0000],\n","         [-0.2311, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.6386,  0.2057,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [ 1.0981, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]],\n","\n","        [[ 0.7983,  0.2574, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [-1.1008, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.0468, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.0072,  0.2230,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [ 0.2873, -0.1040,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [-1.7200, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.2947, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.8281, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.4915, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.1451, -0.3793,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-1.1254, -0.2072,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [-0.9289, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-1.9681, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.2038, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [ 0.0564,  0.1541,  0.3526, -0.3457,  0.0000,  0.0000],\n","         [-0.8355, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","         [-0.4891,  1.3071, -0.3620,  0.4634,  0.0000,  0.0000],\n","         [ 1.2799, -0.0868,  0.1144, -0.0760,  0.0000,  0.0000],\n","         [-0.0517,  0.3090, -0.1238,  0.1937,  0.0000,  0.0000],\n","         [-0.6611, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]]])\n","tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.]])\n","-------\n","torch.Size([8, 20, 6])\n","torch.Size([8, 20])\n"]}]},{"cell_type":"code","source":["print(type(train_loader))\n","print(dir(train_loader))\n","length_train = 0\n","length_test = 0\n","c = 0\n","\n","#training data\n","for nth_batch, (batch,_) in enumerate(train_loader):\n","  #print(len(batch))\n","  c += 1\n","  length_train += len(batch)\n","  if c == 1:\n","    print('the first batch')\n","    print(f'length of each batch is (window size)- {len(batch[0])}')\n","    #each tensor below had 20X25 2D form where 20 is the window size, 25 is fixed in the initial data\n","    print(batch[0])\n","    print(batch[1])\n","    print(batch[2])\n","    print(batch[3])\n","    print(batch[4])\n","    print(batch[5])\n","    print(batch[6])\n","    print(batch[7])\n","    #print(batch[7])\n","print(length_train)\n","print(f'the number of rows in training data = {length_train}')\n","print(f'the number of batches in training data = {nth_batch}')\n","#test data\n","for nth_batch, (batch,_) in enumerate(test_loader):\n","  #print(len(batch))\n","  length_test += len(batch)\n","print(f'the number of rows in testing data = {length_test}')\n","print(f'the number of batches in testing data = {nth_batch}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65rTwdk46isu","executionInfo":{"status":"ok","timestamp":1692644025637,"user_tz":240,"elapsed":20,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"e8fcd094-88fc-4b7f-b31c-b444f94abc2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.utils.data.dataloader.DataLoader'>\n","['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']\n","the first batch\n","length of each batch is (window size)- 20\n","tensor([[-1.0148, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.7495, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.2136,  0.2057,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 1.5084,  2.6149, -2.2677,  2.6208,  0.0000,  0.0000],\n","        [ 1.4469,  0.5155, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [-0.0960, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.2117, -0.3621, -0.1238, -0.3457,  0.0000,  0.0000],\n","        [-0.1083, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.6733,  0.4811, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [-0.4080, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.4925,  0.1713, -0.6003,  0.1937,  0.0000,  0.0000],\n","        [-0.5284, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.7593, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.3932, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.0320, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.4421, -0.2072, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [ 0.3536,  1.5996, -0.8385,  1.0027,  0.0000,  0.0000],\n","        [ 1.4961, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.3241,  2.4600, -2.5060,  2.8905,  0.0000,  0.0000],\n","        [-0.3122,  0.6532, -0.3620,  0.4634,  0.0000,  0.0000]])\n","tensor([[-0.4080, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.4925,  0.1713, -0.6003,  0.1937,  0.0000,  0.0000],\n","        [-0.5284, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.7593, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.3932, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.0320, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.4421, -0.2072, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [ 0.3536,  1.5996, -0.8385,  1.0027,  0.0000,  0.0000],\n","        [ 1.4961, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.3241,  2.4600, -2.5060,  2.8905,  0.0000,  0.0000],\n","        [-0.3122,  0.6532, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [ 2.7250,  5.7468, -7.9848,  4.7783,  0.0000,  0.0000],\n","        [-0.1156,  2.3740, -1.0767,  1.2724,  0.0000,  0.0000],\n","        [-0.6168, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.2949, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3217, -0.3105,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 1.1128, -0.3793,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [-0.9755, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-2.1548, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.1820, -0.2589, -0.1238,  0.1937,  0.0000,  0.0000]])\n","tensor([[-0.7593, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.3932, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.0320, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.4421, -0.2072, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [ 0.3536,  1.5996, -0.8385,  1.0027,  0.0000,  0.0000],\n","        [ 1.4961, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.3241,  2.4600, -2.5060,  2.8905,  0.0000,  0.0000],\n","        [-0.3122,  0.6532, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [ 2.7250,  5.7468, -7.9848,  4.7783,  0.0000,  0.0000],\n","        [-0.1156,  2.3740, -1.0767,  1.2724,  0.0000,  0.0000],\n","        [-0.6168, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.2949, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3217, -0.3105,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 1.1128, -0.3793,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [-0.9755, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-2.1548, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.1820, -0.2589, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [-0.3662,  1.2899, -2.0295,  1.5421,  0.0000,  0.0000],\n","        [-0.2999, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5898, -0.3105,  0.3526, -0.3457,  0.0000,  0.0000]])\n","tensor([[ 0.5698, -0.3277, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [-1.1917, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.8032, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.2136, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.9239, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.4568, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5077,  0.9457, -1.3149,  1.0027,  0.0000,  0.0000],\n","        [ 0.3590,  1.1350, -1.3149,  1.0027,  0.0000,  0.0000],\n","        [-1.1991,  0.0853, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [ 0.2357, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.4666,  2.2879, -1.5531,  1.8118,  0.0000,  0.0000],\n","        [ 2.6459,  0.0681, -0.6003,  0.7331,  0.0000,  0.0000],\n","        [-0.4915, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5996,  0.7220,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [-0.5235,  1.4447, -1.0767,  1.2724,  0.0000,  0.0000],\n","        [ 1.0346, -0.0696, -0.1238, -0.0760,  0.0000,  0.0000],\n","        [-0.3662, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3364, -0.2761,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 0.4450,  1.2210, -1.5531,  1.5421,  0.0000,  0.0000],\n","        [ 0.3438, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000]])\n","tensor([[-0.9239, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.4568, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5077,  0.9457, -1.3149,  1.0027,  0.0000,  0.0000],\n","        [ 0.3590,  1.1350, -1.3149,  1.0027,  0.0000,  0.0000],\n","        [-1.1991,  0.0853, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [ 0.2357, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.4666,  2.2879, -1.5531,  1.8118,  0.0000,  0.0000],\n","        [ 2.6459,  0.0681, -0.6003,  0.7331,  0.0000,  0.0000],\n","        [-0.4915, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5996,  0.7220,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [-0.5235,  1.4447, -1.0767,  1.2724,  0.0000,  0.0000],\n","        [ 1.0346, -0.0696, -0.1238, -0.0760,  0.0000,  0.0000],\n","        [-0.3662, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3364, -0.2761,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 0.4450,  1.2210, -1.5531,  1.5421,  0.0000,  0.0000],\n","        [ 0.3438, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 0.5182, -0.5686, -0.1238, -0.6153,  0.0000,  0.0000],\n","        [ 0.4519, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.6021, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3586, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]])\n","tensor([[ 1.1448, -0.0524, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [-1.2286, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-1.0738,  0.4983, -0.8385,  1.0027,  0.0000,  0.0000],\n","        [-1.1500, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.4298, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [-2.3710, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.1281, -0.5686, -0.3620, -0.6153,  0.0000,  0.0000],\n","        [ 0.7664,  2.2879, -2.5060,  2.8905,  0.0000,  0.0000],\n","        [ 0.6951, -0.2933,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [-0.2655, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.6927,  0.8252, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [-0.0935, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.9657, -0.4998,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 0.0220, -0.2761,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [ 2.0317,  0.2574, -0.6003,  0.7331,  0.0000,  0.0000],\n","        [-1.0222, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.4596,  0.0853, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [ 1.7167, -0.4654,  0.1144, -0.3457,  0.0000,  0.0000],\n","        [ 0.6607,  0.9113, -0.6003,  0.7331,  0.0000,  0.0000],\n","        [-0.2311, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000]])\n","tensor([[ 1.2430, -0.2589,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [-0.8060, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.9903, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.9583,  1.8061, -1.3149,  1.5421,  0.0000,  0.0000],\n","        [ 0.8008,  3.8367, -3.4588,  3.9692,  0.0000,  0.0000],\n","        [ 0.7250, -0.1040, -0.8385,  0.4634,  0.0000,  0.0000],\n","        [ 2.8310,  4.0432, -4.6499,  5.0479,  0.0000,  0.0000],\n","        [ 0.2176,  0.8252, -1.0767,  1.0027,  0.0000,  0.0000],\n","        [-0.4326,  0.1197, -0.1238,  0.1937,  0.0000,  0.0000],\n","        [-0.1967, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.2090, -0.1556,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [-0.2065, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.4105,  3.0623, -1.0767,  1.2724,  0.0000,  0.0000],\n","        [-0.4105, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.5158, -0.0868,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [ 1.0317, -0.3449,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [ 0.5600, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.8379, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5824, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.9163, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]])\n","tensor([[ 0.3590,  1.1350, -1.3149,  1.0027,  0.0000,  0.0000],\n","        [-1.1991,  0.0853, -0.3620,  0.4634,  0.0000,  0.0000],\n","        [ 0.2357, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 1.4666,  2.2879, -1.5531,  1.8118,  0.0000,  0.0000],\n","        [ 2.6459,  0.0681, -0.6003,  0.7331,  0.0000,  0.0000],\n","        [-0.4915, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.5996,  0.7220,  0.1144, -0.0760,  0.0000,  0.0000],\n","        [-0.5235,  1.4447, -1.0767,  1.2724,  0.0000,  0.0000],\n","        [ 1.0346, -0.0696, -0.1238, -0.0760,  0.0000,  0.0000],\n","        [-0.3662, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3364, -0.2761,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 0.4450,  1.2210, -1.5531,  1.5421,  0.0000,  0.0000],\n","        [ 0.3438, -0.4482,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [ 0.5182, -0.5686, -0.1238, -0.6153,  0.0000,  0.0000],\n","        [ 0.4519, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.6021, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3586, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [-0.2286,  0.2746,  0.3526, -0.3457,  0.0000,  0.0000],\n","        [-0.5972, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000],\n","        [ 0.3070, -0.5686,  0.5908, -0.6153,  0.0000,  0.0000]])\n","233\n","the number of rows in training data = 233\n","the number of batches in training data = 29\n","the number of rows in testing data = 65\n","the number of batches in testing data = 8\n"]}]},{"cell_type":"code","source":["233+65"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzVv2JwD6yCw","executionInfo":{"status":"ok","timestamp":1692644025637,"user_tz":240,"elapsed":14,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"e4bbfc06-95dc-4f42-8395-699f6acb5446"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["298"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["---\n","3. Embeddings\n","---"],"metadata":{"id":"ZoaZIHW258KT"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils import weight_norm\n","import math"],"metadata":{"id":"FDaKkd5s1gEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        # Compute the positional encodings once in log space.\n","        super(PositionalEmbedding, self).__init__()\n","\n","        #d_model is the dimension of the embedding. This means that each token in the embedding layer will have a representation of d_model dimensions.\n","        #The d_model dimension is a hyperparameter that can be tuned to improve the performance of the model\n","        #its been set to 128 in the paper\n","        pe = torch.zeros(max_len, d_model).float()\n","        #setting require_grad to TRUE allows the gradient of the positional encoding matrix to be calculated during backpropagation.\n","        #This allows the model to learn the optimal positional encoding matrix for the given task.\n","        #not sure why its been set to False for now\n","        pe.require_grad = False\n","\n","        #The torch.arange() function creates a sequence of numbers from 0 to max_len.\n","        #The float() function converts the sequence of numbers to floating point numbers\n","        #The unsqueeze() function adds a new dimension to the tensor.\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        #The div_term tensor is created by first creating a sequence of numbers from 0 to d_model in steps of 2.\n","        #The sequence of numbers is then converted to floating point numbers and multiplied by a negative exponential function.\n","        #The negative exponential function is used to create a decaying function that decreases as the position increases.\n","        #The div_term tensor is then used to create the positional encoding matrix.\n","        #The positional encoding matrix is a 2D tensor that has the same shape as the input sequences.\n","        #The values in the positional encoding matrix are calculated by taking the div_term tensor and adding it to a sinusoid function.\n","        #The sinusoid function is used to create a wave-like pattern that represents the position of the token in the sequence.\n","        #The positional encoding matrix is then added to the input sequences before they are passed to the model.\n","        #The positional encoding helps the model learn the temporal relationships between the input sequences.\n","        #This is important for tasks such as machine translation and natural language understanding,\n","        #where the order of the words in the sequence is important.\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    #The forward function is not called when the model is initialized.\n","    #The forward function is only called when the model is used to make predictions or calculate the loss.\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__ >= '1.5.0' else 2\n","        #1D convolutional layers are used to extract features from sequences.\n","        #In the case of the TokenEmbedding class, the 1D convolutional layer is used to extract features from the token sequences.\n","        #The 1D convolutional layer takes the token sequences as input and outputs a sequence of features.\n","        #The number of features in the output sequence depends on the number of filters in the 1D convolutional layer.\n","        #The filters in the 1D convolutional layer are learned during training.\n","\n","        #kernel_size specifies the size of th ekernel in the 1D convolution\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n","\n","        #self.modules is a dictionary that contains all of the submodules of the TokenEmbedding class.\n","        #The TokenEmbedding class has two submodules: positional_encoding and conv1d.\n","        #The positional_encoding submodule is a positional encoding layer that is used to add positional information to the input sequences.\n","        #The conv1d submodule is a 1D convolutional layer that is used to extract features from the token sequences.\n","        #The self.modules attribute is used to access the submodules of the TokenEmbedding class.\n","        #For example, the following code snippet can be used to access the positional_encoding submodule:\n","        #     model = TokenEmbedding()\n","        #     positional_encoding = model.modules['positional_encoding']\n","        for m in self.modules():\n","            #if the token embedding exists for the submodule\n","            if isinstance(m, nn.Conv1d):\n","                #The nn.init.kaiming_normal_ function in PyTorch is used to initialize the weights of a neural network layer.\n","                #The function initializes the weights using a normal distribution with a variance that is inversely proportional to the fan-in of the layer.\n","                #It is often used in conjunction with ReLU activation functions.\n","                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        #forward does 3 things-\n","        #1. Permutes the input tensor x so that the batch dimension is the first dimension, the sequence dimension is the second dimension, and the feature dimension is the third dimension.\n","        #2. Pass the permuted tensor x to the tokenConv layer.\n","        #3. Transposes the output tensor of the tokenConv layer so that the sequence dimension is the first dimension and the feature dimension is the second dimension.\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n","        return x\n","\n","\n","class DataEmbedding(nn.Module):\n","    #the c_in taken here is nothing but enc_in size- here input_c = 25 and output_c = 25 (see shell script, these are parameters taken by the parser)\n","    #note: see build_model in the main.py file- the model is initilaized using the input_c = 25 and output_c = 25\n","    def __init__(self, c_in, d_model, dropout=0.0):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x):\n","        x = self.value_embedding(x) + self.position_embedding(x)\n","        return self.dropout(x)\n"],"metadata":{"id":"J60-ExPD6XtU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["can skip: the code below in this section is simply to experiment with the embeddings, embeddings will be called again in the main model"],"metadata":{"id":"rQXmimLj-KDv"}},{"cell_type":"code","source":["# Encoding for the train\n","enc_in = 6 #embedding size here as there are 6 columns (25 for SMAP)\n","embedding = DataEmbedding(c_in=enc_in, d_model=512, dropout=0.0) #create an object of class DataEmbedding\n","print(embedding)\n","print(type(embedding))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usnQRAGE7Szp","executionInfo":{"status":"ok","timestamp":1692644025637,"user_tz":240,"elapsed":7,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"339cfb0b-1872-4904-ad48-9abc10deacb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataEmbedding(\n","  (value_embedding): TokenEmbedding(\n","    (tokenConv): Conv1d(6, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n","  )\n","  (position_embedding): PositionalEmbedding()\n","  (dropout): Dropout(p=0.0, inplace=False)\n",")\n","<class '__main__.DataEmbedding'>\n"]}]},{"cell_type":"code","source":["#trying to understand how the embedding class works\n","#calculate all the embdeddings for the training set\n","for nth_batch, (batch,sigma) in enumerate(train_loader):\n","  batch_embedding = embedding(batch)\n","  #print details for only the first batch\n","  if nth_batch == 0:\n","    print(batch_embedding.shape) #batch_size X win_size X d_model=512\n","    print(len(batch_embedding)) #8\n","    print(batch_embedding[0].shape) #20 x 512\n","    print(len(batch_embedding[0])) #20\n","    print(batch_embedding[1].shape) #20 x 512\n","    print(len(batch_embedding[1])) #20\n","    print(batch_embedding[2].shape) #20 x 512\n","    print(len(batch_embedding[2])) #20\n","    #'the size of each embedding is 20X512 which is win_size X d_model\n","    #print a sample embedding\n","    print(batch_embedding[0]) #20 X 512\n","  else:\n","    print(f\"calculating embedding for batch number {nth_batch}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFcDghPQ7YUc","executionInfo":{"status":"ok","timestamp":1692644025995,"user_tz":240,"elapsed":363,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"f53568b8-c7e3-4d5c-b474-bcff262e188c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 20, 512])\n","8\n","torch.Size([20, 512])\n","20\n","torch.Size([20, 512])\n","20\n","torch.Size([20, 512])\n","20\n","tensor([[-0.7407,  0.9948, -0.9496,  ...,  0.4293, -0.2279,  1.4734],\n","        [ 0.2744,  1.1608,  1.8418,  ...,  2.4348,  0.3173,  1.3905],\n","        [ 0.2945, -0.5628,  1.4821,  ...,  0.6740, -0.7632,  1.1076],\n","        ...,\n","        [ 1.9874,  0.9152,  1.8212,  ...,  3.0008,  3.1786,  1.5899],\n","        [-1.0686,  0.5923, -3.1183,  ...,  1.6509, -0.3847, -1.5276],\n","        [-0.0545, -1.5366,  0.0997,  ..., -0.8847, -2.9411,  0.5008]],\n","       grad_fn=<SelectBackward0>)\n","calculating embedding for batch number 1\n","calculating embedding for batch number 2\n","calculating embedding for batch number 3\n","calculating embedding for batch number 4\n","calculating embedding for batch number 5\n","calculating embedding for batch number 6\n","calculating embedding for batch number 7\n","calculating embedding for batch number 8\n","calculating embedding for batch number 9\n","calculating embedding for batch number 10\n","calculating embedding for batch number 11\n","calculating embedding for batch number 12\n","calculating embedding for batch number 13\n","calculating embedding for batch number 14\n","calculating embedding for batch number 15\n","calculating embedding for batch number 16\n","calculating embedding for batch number 17\n","calculating embedding for batch number 18\n","calculating embedding for batch number 19\n","calculating embedding for batch number 20\n","calculating embedding for batch number 21\n","calculating embedding for batch number 22\n","calculating embedding for batch number 23\n","calculating embedding for batch number 24\n","calculating embedding for batch number 25\n","calculating embedding for batch number 26\n","calculating embedding for batch number 27\n","calculating embedding for batch number 28\n","calculating embedding for batch number 29\n"]}]},{"cell_type":"markdown","source":["note: for each row, teh embedding is calculated of 20X512. Each bath conatins 8 datapoints (or rows) so the entire dimension of a batch is 8X20X512. The 6 (from enc_in is no longer used)"],"metadata":{"id":"FINBDxvs9GsL"}},{"cell_type":"markdown","source":["---\n","4. Attention\n","---"],"metadata":{"id":"5zT6_mtJ9ylJ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import math\n","from math import sqrt\n","import os\n"],"metadata":{"id":"C9_FqbME8QWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#used to create a mask that prevents the model from attending to future tokens when predicting the current token.\n","#The mask is a triangular matrix where the diagonal elements are all 1 and the off-diagonal elements are all 0\n","#This ensures that the model only learns dependencies between the current token and the tokens that have already been seen\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        #define the mask shape- to be B=batch size, L=sequence length, notice L is being passed to the mask function\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","\n","class AnomalyAttention(nn.Module):\n","    def __init__(self, win_size, mask_flag=True, scale=None, attention_dropout=0.0, output_attention=False):\n","        super(AnomalyAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        window_size = win_size\n","        #tensor that stores the distances between all pairs of sequences in the dataset.\n","        #The distances are calculated using the Euclidean distance metric\n","        self.distances = torch.zeros((window_size, window_size)).cuda()\n","        for i in range(window_size):\n","            for j in range(window_size):\n","                self.distances[i][j] = abs(i - j)\n","\n","    def forward(self, queries, keys, values, sigma, attn_mask):\n","       #B : The batch size= 2 in the paper I think., L : The sequence length=10 i think,\n","       #H : The hidden size of the transformer=128, E : The embedding size=25. #H = head?\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        #scaling to prevent attention weights from becoming too large\n","        scale = self.scale or 1. / sqrt(E)\n","\n","        #the shape of scores is B L H S (Note: I think S denotes the same thing as L, both represent sequence length)\n","        #The scores tensor contains the attention scores between the queries and keys tensors\n","        #teh code below specifies the tensor contraction to be performed\n","        #blhe: The first part of the string specifies the shape of the first tensor, which is the queries tensor. The blhe shape indicates that the queries tensor has four dimensions: batch size (b), sequence length (l), hidden size (h), and embedding size (e).\n","        #bshe: The second part of the string specifies the shape of the second tensor, which is the keys tensor. The bshe shape indicates that the keys tensor has the same shape as the queries tensor.\n","        #->: The -> symbol indicates that the tensor contractions should be performed.\n","        #bhls: The third part of the string specifies the shape of the output tensor, which is the scores tensor. The bhls shape indicates that the scores tensor has four dimensions: batch size (b), sequence length (l), hidden size (h), and sequence length (l) again.\n","        #the following tensor contractions are perfomed-\n","        #1. The queries tensor is multiplied by the keys tensor.\n","        #2. The product of the queries tensor and the keys tensor is summed over the embedding size dimension.\n","        #3. The sum of the products is then reshaped to have the shape of the scores tensor.\n","\n","        #note: S and E need not be same\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","\n","\n","        #apply mask if needed\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        #scale\n","        attn = scale * scores\n","\n","        sigma = sigma.transpose(1, 2)  # B L H ->  B H L\n","        window_size = attn.shape[-1]\n","        sigma = torch.sigmoid(sigma * 5) + 1e-5\n","        sigma = torch.pow(3, sigma) - 1\n","        sigma = sigma.unsqueeze(-1).repeat(1, 1, 1, window_size)  # B H L L #I think this is the same dimension as the scores\n","        prior = self.distances.unsqueeze(0).unsqueeze(0).repeat(sigma.shape[0], sigma.shape[1], 1, 1).cuda()\n","        prior = 1.0 / (math.sqrt(2 * math.pi) * sigma) * torch.exp(-prior ** 2 / 2 / (sigma ** 2))\n","\n","        series = self.dropout(torch.softmax(attn, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", series, values)\n","\n","        if self.output_attention:\n","            return (V.contiguous(), series, prior, sigma)\n","        else:\n","            return (V.contiguous(), None)\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, d_keys=None,\n","                 d_values=None):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model // n_heads)\n","        d_values = d_values or (d_model // n_heads)\n","        self.norm = nn.LayerNorm(d_model)\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model,\n","                                          d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model,\n","                                        d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model,\n","                                          d_values * n_heads)\n","        self.sigma_projection = nn.Linear(d_model,\n","                                          n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","\n","        self.n_heads = n_heads\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","        x = queries\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","        sigma = self.sigma_projection(x).view(B, L, H)\n","\n","        out, series, prior, sigma = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            sigma,\n","            attn_mask\n","        )\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), series, prior, sigma\n"],"metadata":{"id":"EhPaLbtn90YW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["can skip: the code below in this section is simply to experiment with the attention, attention will be called again in the main model"],"metadata":{"id":"UVLdfWpjArRc"}},{"cell_type":"code","source":["#creating a smaple attentionlayer to understand class structure\n","y = AnomalyAttention(win_size=20, mask_flag=False, scale=None, attention_dropout=0.0, output_attention=False)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-xmcMsu-kY4","executionInfo":{"status":"ok","timestamp":1692644025996,"user_tz":240,"elapsed":10,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"b4726a5f-ec19-4ec0-8fab-cdc38ca883a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AnomalyAttention(\n","  (dropout): Dropout(p=0.0, inplace=False)\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["b = AttentionLayer(y,d_model=512,n_heads=8)\n","b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b_g_9fO_8wG","executionInfo":{"status":"ok","timestamp":1692644025996,"user_tz":240,"elapsed":7,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"84e8f111-f760-4287-f1b2-c34976d4aba1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AttentionLayer(\n","  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  (inner_attention): AnomalyAttention(\n","    (dropout): Dropout(p=0.0, inplace=False)\n","  )\n","  (query_projection): Linear(in_features=512, out_features=512, bias=True)\n","  (key_projection): Linear(in_features=512, out_features=512, bias=True)\n","  (value_projection): Linear(in_features=512, out_features=512, bias=True)\n","  (sigma_projection): Linear(in_features=512, out_features=8, bias=True)\n","  (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["---\n","5. Encoder\n","---"],"metadata":{"id":"UK3ukQfR-XGH"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        ## -- what is dff compared to d_model\n","        d_ff = d_ff or 4 * d_model\n","        self.attention = attention\n","        #convolution for learning important imformation\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","\n","        #Layer normalization is a technique used to normalize\n","        #the activations of a layer, which can help to improve the stability and performance of the model\n","        #imporves performance of models\n","        self.norm2 = nn.LayerNorm(d_model)\n","        #dropout prevent overfitting in neural networks\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    ## -- how is forward called immedietly?\n","    def forward(self, x, attn_mask=None):\n","        new_x, attn, mask, sigma = self.attention(x, x, x,attn_mask=attn_mask)\n","        #dropout prevent overfitting in neural networks\n","        x = x + self.dropout(new_x)\n","        #again norm followed by dropout\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n","        y = self.dropout(self.conv2(y).transpose(-1, 1))\n","\n","        ## -- why taking a combination of x and y?\n","        return self.norm2(x + y), attn, mask, sigma\n","\n","\n","class Encoder(nn.Module):\n","    #note the EncoderLayer is passed to the encoder\n","    def __init__(self, attn_layers, norm_layer=None):\n","        super(Encoder, self).__init__()\n","\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.norm = norm_layer\n","\n","    #only appending in teh encoder layer\n","    def forward(self, x, attn_mask=None):\n","        #note here B= batch, L= layers stacked on top of each other, D=?\n","\n","        ### x [B, L, D]\n","        series_list = []\n","        prior_list = []\n","        sigma_list = []\n","        for attn_layer in self.attn_layers:\n","            x, series, prior, sigma = attn_layer(x, attn_mask=attn_mask)\n","            series_list.append(series)\n","            prior_list.append(prior)\n","            sigma_list.append(sigma)\n","        if self.norm is not None:\n","            x = self.norm(x)\n","        #returns appended\n","        return x, series_list, prior_list, sigma_list\n","\n","\n","class AnomalyTransformer(nn.Module):\n","    def __init__(self, win_size, enc_in, c_out, d_model=512, n_heads=8, e_layers=3, d_ff=512,\n","                 dropout=0.0, activation='gelu', output_attention=True):\n","        super(AnomalyTransformer, self).__init__()\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.embedding = DataEmbedding(enc_in, d_model, dropout)\n","\n","        # Encoder\n","        #the anomaloy transformer is created by passing the anomaly attention\n","        #inside the attention layer which is passed to encoder layer where\n","        #its further passed to the encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(\n","                        AnomalyAttention(win_size, False, attention_dropout=dropout, output_attention=output_attention),\n","                        d_model, n_heads),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","\n","        ## -- what is this projection\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","\n","    def forward(self, x):\n","        enc_out = self.embedding(x)\n","        enc_out, series, prior, sigmas = self.encoder(enc_out)\n","        enc_out = self.projection(enc_out)\n","\n","        if self.output_attention:\n","            return enc_out, series, prior, sigmas\n","        else:\n","            return enc_out  # [B, L, D]\n"],"metadata":{"id":"5fWylVjL94dS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","6. Main\n","---"],"metadata":{"id":"ul8ufgDaA4lS"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","import time\n","from sklearn import metrics\n","import matplotlib.pyplot as plt"],"metadata":{"id":"cAXKn5k6-dJo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def my_kl_loss(p, q):\n","\n","    #calculates the difference between the logarithms of p and q and multiplies into p\n","    res = p * (torch.log(p + 0.0001) - torch.log(q + 0.0001))\n","\n","    #take the sum and the mean across columns\n","    ## --not sure why mean is again dim = 1\n","    return torch.mean(torch.sum(res, dim=-1), dim=1)"],"metadata":{"id":"eAL6yRrmA6jq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def adjust_learning_rate(optimizer, epoch, lr_):\n","    #create a dictionary for epoch\n","    lr_adjust = {epoch: lr_ * (0.5 ** ((epoch - 1) // 1))}\n","    #the learning rate is adjusted according to teh number of epochs completed\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))"],"metadata":{"id":"9JlgNiLmA8bj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["omitted early stopping class"],"metadata":{"id":"sBOPYzqPBMYM"}},{"cell_type":"code","source":["class Solver(object):\n","    DEFAULTS = {}\n","\n","    def __init__(self, config):\n","\n","        self.__dict__.update(Solver.DEFAULTS, **config)\n","\n","        #only considered the loaders required\n","        #self.train_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,mode='train',dataset=self.dataset)\n","        self.train_loader = get_loader_segment(batch_size=self.batch_size, win_size=self.win_size,mode='train')\n","        #self.vali_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,mode='val',dataset=self.dataset)\n","        #self.test_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,mode='test',dataset=self.dataset)\n","        self.test_loader = get_loader_segment(batch_size=self.batch_size, win_size=self.win_size,mode='test')\n","        #self.thre_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,mode='thre',dataset=self.dataset)\n","        self.thre_loader = get_loader_segment(batch_size=self.batch_size, win_size=self.win_size,mode='thre')\n","\n","        self.build_model()\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.criterion = nn.MSELoss()\n","\n","    def build_model(self):\n","        self.model = AnomalyTransformer(win_size=self.win_size, enc_in=self.input_c, c_out=self.output_c, e_layers=3)\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n","\n","        if torch.cuda.is_available():\n","            self.model.cuda()\n","\n","    def vali(self, vali_loader):\n","        self.model.eval()\n","\n","        loss_1 = []\n","        loss_2 = []\n","        for i, (input_data, _) in enumerate(vali_loader):\n","            input = input_data.float().to(self.device)\n","            output, series, prior, _ = self.model(input)\n","            series_loss = 0.0\n","            prior_loss = 0.0\n","            for u in range(len(prior)):\n","                series_loss += (torch.mean(my_kl_loss(series[u], (\n","                        prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n","                                                                                               self.win_size)).detach())) + torch.mean(\n","                    my_kl_loss(\n","                        (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n","                                                                                                self.win_size)).detach(),\n","                        series[u])))\n","                prior_loss += (torch.mean(\n","                    my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n","                                                                                                       self.win_size)),\n","                               series[u].detach())) + torch.mean(\n","                    my_kl_loss(series[u].detach(),\n","                               (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,\n","                                                                                                       self.win_size)))))\n","            series_loss = series_loss / len(prior)\n","            prior_loss = prior_loss / len(prior)\n","\n","            rec_loss = self.criterion(output, input)\n","            loss_1.append((rec_loss - self.k * series_loss).item())\n","            loss_2.append((rec_loss + self.k * prior_loss).item())\n","\n","        return np.average(loss_1), np.average(loss_2)\n","\n","\n","    def train(self):\n","\n","        print(\"======================TRAIN MODE======================\")\n","\n","        time_now = time.time()\n","        #path = self.model_save_path\n","        #if not os.path.exists(path):\n","            #os.makedirs(path)\n","        #early_stopping = EarlyStopping(patience=3, verbose=True, dataset_name=self.dataset)\n","        train_steps = len(self.train_loader)\n","\n","        for epoch in range(self.num_epochs):\n","            iter_count = 0\n","            loss1_list = []\n","\n","            epoch_time = time.time()\n","            self.model.train()\n","            #for i, (input_data, labels) in enumerate(self.train_loader):\n","            for i, (input_data) in enumerate(self.train_loader):\n","\n","                self.optimizer.zero_grad()\n","                iter_count += 1\n","                input = input_data.float().to(self.device)\n","\n","                output, series, prior, _ = self.model(input)\n","\n","                # calculate Association discrepancy\n","                series_loss = 0.0\n","                prior_loss = 0.0\n","                for u in range(len(prior)):\n","                    series_loss += (torch.mean(my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach())) + torch.mean(my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach(),series[u])))\n","                    prior_loss += (torch.mean(my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),series[u].detach())) + torch.mean(my_kl_loss(series[u].detach(), (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)))))\n","                series_loss = series_loss / len(prior)\n","                prior_loss = prior_loss / len(prior)\n","\n","                rec_loss = self.criterion(output, input)\n","\n","                loss1_list.append((rec_loss - self.k * series_loss).item())\n","                loss1 = rec_loss - self.k * series_loss\n","                loss2 = rec_loss + self.k * prior_loss\n","\n","                if (i + 1) % 100 == 0:\n","                    speed = (time.time() - time_now) / iter_count\n","                    left_time = speed * ((self.num_epochs - epoch) * train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","\n","                # Minimax strategy\n","                loss1.backward(retain_graph=True)\n","                loss2.backward()\n","                self.optimizer.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n","            train_loss = np.average(loss1_list)\n","\n","            vali_loss1, vali_loss2 = self.vali(self.test_loader)\n","\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} \".format(epoch + 1, train_steps, train_loss, vali_loss1))\n","            '''\n","            early_stopping(vali_loss1, vali_loss2, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","            adjust_learning_rate(self.optimizer, epoch + 1, self.lr)\n","            '''\n","\n","    def test(self):\n","        #self.model.load_state_dict(\n","            #torch.load(\n","                #os.path.join(str(self.model_save_path), str(self.dataset) + '_checkpoint.pth')))\n","        self.model.eval()\n","        temperature = 50\n","\n","        print(\"======================TEST MODE======================\")\n","\n","        criterion = nn.MSELoss(reduce=False)\n","\n","        # (1) stastic on the train set\n","        attens_energy = []\n","        #for i, (input_data, labels) in enumerate(self.train_loader):\n","        for i, (input_data, labels) in enumerate(self.test_loader):\n","            input = input_data.float().to(self.device)\n","            output, series, prior, _ = self.model(input)\n","            loss = torch.mean(criterion(input, output), dim=-1)\n","            series_loss = 0.0\n","            prior_loss = 0.0\n","            for u in range(len(prior)):\n","                if u == 0:\n","                    series_loss = my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach()) * temperature\n","                    prior_loss = my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),series[u].detach()) * temperature\n","                else:\n","                    series_loss += my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach()) * temperature\n","                    prior_loss += my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),series[u].detach()) * temperature\n","\n","            metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n","            cri = metric * loss\n","            cri = cri.detach().cpu().numpy()\n","            attens_energy.append(cri)\n","\n","        attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n","        train_energy = np.array(attens_energy)\n","\n","        # (2) find the threshold\n","        attens_energy = []\n","        for i, (input_data, labels) in enumerate(self.thre_loader):\n","            input = input_data.float().to(self.device)\n","            output, series, prior, _ = self.model(input)\n","\n","            loss = torch.mean(criterion(input, output), dim=-1)\n","\n","            series_loss = 0.0\n","            prior_loss = 0.0\n","            for u in range(len(prior)):\n","                if u == 0:\n","                    series_loss = my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach()) * temperature\n","                    prior_loss = my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),series[u].detach()) * temperature\n","                else:\n","                    series_loss += my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach()) * temperature\n","                    prior_loss += my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),series[u].detach()) * temperature\n","            # Metric\n","            metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n","            cri = metric * loss\n","            cri = cri.detach().cpu().numpy()\n","            attens_energy.append(cri)\n","\n","        attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n","        test_energy = np.array(attens_energy)\n","        combined_energy = np.concatenate([train_energy, test_energy], axis=0)\n","        thresh = np.percentile(combined_energy, 100 - self.anormly_ratio)\n","        print(\"Threshold :\", thresh)\n","\n","        # (3) evaluation on the test set\n","        test_labels = []\n","        attens_energy = []\n","        for i, (input_data, labels) in enumerate(self.thre_loader):\n","            input = input_data.float().to(self.device)\n","            output, series, prior, _ = self.model(input)\n","\n","            loss = torch.mean(criterion(input, output), dim=-1)\n","\n","            series_loss = 0.0\n","            prior_loss = 0.0\n","            for u in range(len(prior)):\n","                if u == 0:\n","                    series_loss = my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach()) * temperature\n","                    prior_loss = my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),series[u].detach()) * temperature\n","                else:\n","                    series_loss += my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)).detach()) * temperature\n","                    prior_loss += my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,self.win_size)),\n","                        series[u].detach()) * temperature\n","            metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n","\n","            cri = metric * loss\n","            cri = cri.detach().cpu().numpy()\n","            attens_energy.append(cri)\n","            test_labels.append(labels)\n","\n","        attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n","        test_labels = np.concatenate(test_labels, axis=0).reshape(-1)\n","        test_energy = np.array(attens_energy)\n","        test_labels = np.array(test_labels)\n","\n","        pred = (test_energy > thresh).astype(int)\n","\n","        gt = test_labels.astype(int)\n","\n","        print(\"pred:   \", pred.shape)\n","        print(\"gt:     \", gt.shape)\n","\n","        '''\n","        # detection adjustment\n","        anomaly_state = False\n","        for i in range(len(gt)):\n","            if gt[i] == 1 and pred[i] == 1 and not anomaly_state:\n","                anomaly_state = True\n","                for j in range(i, 0, -1):\n","                    if gt[j] == 0:\n","                        break\n","                    else:\n","                        if pred[j] == 0:\n","                            pred[j] = 1\n","                for j in range(i, len(gt)):\n","                    if gt[j] == 0:\n","                        break\n","                    else:\n","                        if pred[j] == 0:\n","                            pred[j] = 1\n","            elif gt[i] == 0:\n","                anomaly_state = False\n","            if anomaly_state:\n","                pred[i] = 1\n","        '''\n","        pred = np.array(pred)\n","        gt = np.array(gt)\n","        print(\"pred shape: \", pred.shape)\n","        print(\"gt shape:   \", gt.shape)\n","        print(f\"pred: {pred}\")\n","        print(f\"gt: {gt}\")\n","\n","\n","        fpr, tpr, _ = metrics.roc_curve(gt,  test_energy)\n","        #create ROC curve\n","        plt.plot(fpr,tpr)\n","        plt.ylabel('True Positive Rate')\n","        plt.xlabel('False Positive Rate')\n","        plt.show()\n","\n","        from sklearn.metrics import precision_recall_fscore_support\n","        from sklearn.metrics import accuracy_score\n","        accuracy = accuracy_score(gt, pred)\n","        precision, recall, f_score, support = precision_recall_fscore_support(gt, pred,average='binary')\n","        print(\n","            \"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f} \".format(\n","                accuracy, precision,\n","                recall, f_score))\n","\n","        return accuracy, precision, recall, f_score"],"metadata":{"id":"v0GKlyG9A92V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main(config):\n","    #cudnn.benchmark = True\n","    #if (not os.path.exists(config.model_save_path)):\n","        #mkdir(config.model_save_path)\n","    solver = Solver(config)\n","\n","    #if config.mode == 'train':\n","    solver.train()\n","    #elif config.mode == 'test':\n","    solver.test()\n","\n","    return solver"],"metadata":{"id":"Xk5lYwEnCsXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\"lr\": 1e-4, \"num_epochs\": 2, \"win_size\":20,\"input_c\":6, \"output_c\":6,\"batch_size\":8,\"anormly_ratio\":4.00,\"k\":3}"],"metadata":{"id":"T0RwmoPrJTXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Solver({\"lr\": 1e-4, \"num_epochs\": 2, \"win_size\":20,\"input_c\":6, \"output_c\":6,\"batch_size\":8,\"anormly_ratio\":4.00})"],"metadata":{"id":"8RpQpWy9IxYn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RXl9OohAJPO_","executionInfo":{"status":"ok","timestamp":1692647904524,"user_tz":240,"elapsed":2112,"user":{"displayName":"Sarayu Vyakaranam","userId":"13294961587060716193"}},"outputId":"0c5bfdb3-ac8b-4cf0-94ce-3e253827b2aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test: (84, 6)\n","train: (252, 6)\n","8\n","test: (84, 6)\n","train: (252, 6)\n","8\n","test: (84, 6)\n","train: (252, 6)\n","8\n","======================TRAIN MODE======================\n","Epoch: 1 cost time: 0.7145488262176514\n","Epoch: 1, Steps: 30 | Train Loss: -22.1338828 Vali Loss: -32.9120242 \n","Epoch: 2 cost time: 0.6680958271026611\n","Epoch: 2, Steps: 30 | Train Loss: -35.9658021 Vali Loss: -36.2538478 \n","======================TEST MODE======================\n","here\n","Threshold : 0.038866608589887615\n","here\n","pred:    (80,)\n","gt:      (80,)\n","pred shape:  (80,)\n","gt shape:    (80,)\n","pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 0 0 0 0]\n","gt: [0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n"," 0 0 1 0 1 0]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy : 0.8250, Precision : 0.3333, Recall : 0.0769, F-score : 0.1250 \n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.Solver at 0x7d2c43e50b50>"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":[],"metadata":{"id":"eqbxonhiJZar"},"execution_count":null,"outputs":[]}]}